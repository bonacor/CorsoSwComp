{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red'>Project IRIS: with Keras+sklearn</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial you will discover **how to use Keras+sklearn to develop and evaluate a NN model for a multiclass classification problem**. \n",
    "\n",
    "Goals:\n",
    "* How to load data from CSV and make it available to Keras\n",
    "* How to prepare multiclass classification data for modeling with NNs\n",
    "* How to evaluate Keras NN models with scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description of the input data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The iris flowers dataset is a standard ML dataset, widely used worldwide as benchmark.\n",
    "\n",
    "### Dataset availability:\n",
    "\n",
    "Almost ubiquitous.. e.g.\n",
    "   * [UCI Machine Learning repository](http://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data)\n",
    "\n",
    "More info:\n",
    "   * [UCI Machine Learning Repository page](https://archive.ics.uci.edu/ml/datasets/Iris).\n",
    "\n",
    "Alternatively:\n",
    "   * get it from [https://github.com/bonacor/CorsoSwComp](https://github.com/bonacor/CorsoSwComp) by importing into from Google Colab\n",
    "      * direct URL to the dataset: [https://github.com/bonacor/CorsoSwComp/blob/master/iris.data.csv](https://github.com/bonacor/CorsoSwComp/blob/master/iris.data.csv)\n",
    "\n",
    "### Dataset description:\n",
    "\n",
    "* This is a good example to practice on a multiclass classification problem.\n",
    "* Each instance describes the properties of an observed iris flower measurements\n",
    "* All of the 4 input variables are numeric and have the same scale (cm)\n",
    "   * Sepal length in centimeters \n",
    "   * Sepal width in centimeters \n",
    "   * Petal length in centimeters \n",
    "   * Petal width in centimeters\n",
    "* The output variable is a specific iris species (3 possibilities)\n",
    "   * the \"class\", e.g. \"Iris-setosa\", \"Iris-versicolor\" or \"Iris-verginica\"\n",
    "\n",
    "### How the dataset looks like:\n",
    "\n",
    "\n",
    "    5.1,3.5,1.4,0.2,Iris-setosa\n",
    "    4.9,3.0,1.4,0.2,Iris-setosa\n",
    "    4.7,3.2,1.3,0.2,Iris-setosa\n",
    "    4.6,3.1,1.5,0.2,Iris-setosa\n",
    "    5.0,3.6,1.4,0.2,Iris-setosa\n",
    "    (...)\n",
    "\n",
    "\n",
    "### Additional input from best practitioners:\n",
    "\n",
    "The iris flower dataset is a well studied problem and as such we can expect to achieve a model accuracy in the range of 95% to 97%. USe this as target to aim for when developing your model(s)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Classes and Functions\n",
    "\n",
    "Start by importing all classes and functions you will need:\n",
    "* all the functionality we require from **Keras**\n",
    "* data loading functionalities from **Pandas**\n",
    "* data preparation and model evaluation from **scikit-learn**\n",
    "* more as needed (e.g. **numpy**, **matplotlib**, ..)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "# pandas\n",
    "from pandas import read_csv\n",
    "# matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "# sklearn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize random nb generator\n",
    "\n",
    "Important to ensure that the results we achieve from this model are repeatable, i.e. it ensures that the stochastic process of training a NN model can be reproduced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load The Dataset\n",
    "\n",
    "Download the dataset from the link above and place it in your current working directory, with filename $iris.data.csv$. \n",
    "\n",
    "Then, you can quickly inspect it from this same ipynb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-05-23 13:34:02--  https://raw.githubusercontent.com/bonacor/CorsoSwComp/master/iris.data.csv\n",
      "Resolving raw.githubusercontent.com... 151.101.240.133\n",
      "Connecting to raw.githubusercontent.com|151.101.240.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4551 (4.4K) [text/plain]\n",
      "Saving to: 'iris.data.csv.18'\n",
      "\n",
      "iris.data.csv.18    100%[===================>]   4.44K  --.-KB/s    in 0s      \n",
      "\n",
      "2019-05-23 13:34:02 (19.2 MB/s) - 'iris.data.csv.18' saved [4551/4551]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#today, get it from here for example:\n",
    "!wget https://raw.githubusercontent.com/bonacor/CorsoSwComp/master/iris.data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r--  1 bonacor  staff  4551 May 23 11:03 iris.data.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls -trl iris.data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.1,3.5,1.4,0.2,Iris-setosa\r\n",
      "4.9,3.0,1.4,0.2,Iris-setosa\r\n",
      "4.7,3.2,1.3,0.2,Iris-setosa\r\n",
      "4.6,3.1,1.5,0.2,Iris-setosa\r\n",
      "5.0,3.6,1.4,0.2,Iris-setosa\r\n"
     ]
    }
   ],
   "source": [
    "!head -5 iris.data.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, load the dataset. You can do it in various ways. The output variable contains strings, so it is suggested (easiest) to load the data using **pandas** into a DataFrame. While you do so, split the attributes (i.e. columns) into input variables (the matrix of **features X**) and output variables (the vector **label Y**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "dataframe = read_csv(\"iris.data.csv\", header=None)\n",
    "dataset = dataframe.values\n",
    "X = dataset[:,0:4].astype(float)   # columns from 1st to 4th into X\n",
    "Y = dataset[:,4]                   # column 5th into Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify what you did."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [5.4, 3.4, 1.5, 0.4],\n",
       "       [5.2, 4.1, 1.5, 0.1],\n",
       "       [5.5, 4.2, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [5.1, 3.4, 1.5, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [5.5, 2.3, 4. , 1.3],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [6.7, 3.1, 4.4, 1.4],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [5.5, 2.4, 3.7, 1. ],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [6. , 2.7, 5.1, 1.6],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [5.6, 3. , 4.1, 1.3],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [6.3, 3.3, 6. , 2.5],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [7.1, 3. , 5.9, 2.1],\n",
       "       [6.3, 2.9, 5.6, 1.8],\n",
       "       [6.5, 3. , 5.8, 2.2],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [6.7, 2.5, 5.8, 1.8],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [6.5, 3.2, 5.1, 2. ],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [5.7, 2.5, 5. , 2. ],\n",
       "       [5.8, 2.8, 5.1, 2.4],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [6. , 2.2, 5. , 1.5],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [5.6, 2.8, 4.9, 2. ],\n",
       "       [7.7, 2.8, 6.7, 2. ],\n",
       "       [6.3, 2.7, 4.9, 1.8],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [7.2, 3.2, 6. , 1.8],\n",
       "       [6.2, 2.8, 4.8, 1.8],\n",
       "       [6.1, 3. , 4.9, 1.8],\n",
       "       [6.4, 2.8, 5.6, 2.1],\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [6.3, 2.8, 5.1, 1.5],\n",
       "       [6.1, 2.6, 5.6, 1.4],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [6. , 3. , 4.8, 1.8],\n",
       "       [6.9, 3.1, 5.4, 2.1],\n",
       "       [6.7, 3.1, 5.6, 2.4],\n",
       "       [6.9, 3.1, 5.1, 2.3],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [6.7, 3. , 5.2, 2.3],\n",
       "       [6.3, 2.5, 5. , 1.9],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [5.9, 3. , 5.1, 1.8]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa',\n",
       "       'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa',\n",
       "       'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa',\n",
       "       'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa',\n",
       "       'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa',\n",
       "       'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa',\n",
       "       'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa',\n",
       "       'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa',\n",
       "       'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa',\n",
       "       'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa',\n",
       "       'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa',\n",
       "       'Iris-setosa', 'Iris-setosa', 'Iris-setosa', 'Iris-setosa',\n",
       "       'Iris-setosa', 'Iris-setosa', 'Iris-versicolor', 'Iris-versicolor',\n",
       "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
       "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
       "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
       "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
       "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
       "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
       "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
       "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
       "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
       "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
       "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
       "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
       "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
       "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
       "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
       "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
       "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
       "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
       "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
       "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
       "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
       "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
       "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
       "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
       "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
       "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
       "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
       "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
       "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
       "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
       "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
       "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica',\n",
       "       'Iris-virginica', 'Iris-virginica'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation/preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-hot encoding the output variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*(NOTE: different datasets may require different data manipulation/preprocessing. This applies to this specific case)*\n",
    "\n",
    "When modeling multiclass classification problems using NNs it is practice to reshape the output attribute from a vector that contains values for each class value to a matrix with a boolean for each class value and whether or not a given instance has that class value or not. \n",
    "\n",
    "In my case, the output variable contains 3 different class (string) values, i.e. I can have one of each of these 3 observations:\n",
    "\n",
    "    Iris-setosa\n",
    "    Iris-versicolor\n",
    "    Iris-virginica\n",
    "    \n",
    "I translate this into a one hot encoded binary matrix for each data instance among these 3:\n",
    "\n",
    "    Iris-setosa, Iris-versicolor, Iris-virginica\n",
    "\n",
    "\n",
    "that would hence look as follows:\n",
    "\n",
    "    1, 0, 0\n",
    "    0, 1, 0\n",
    "    0, 0, 1\n",
    "    \n",
    "We can do this easily by:\n",
    "   1. encoding the strings consistently to integers using the scikit-learn class *LabelEncoder*\n",
    "   2. convert the vector of integers to a one-hot encoding using the Keras function *to_categorical()*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# part 1: encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y)\n",
    "encoded_Y = encoder.transform(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# part 2: do one-hot encoding\n",
    "transformed_Y = np_utils.to_categorical(encoded_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define a NN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a baseline model\n",
    "\n",
    "You can create a baseline NN - a simple **Fully Connected NN (FCNN)** - for the IRIS multiclass classification problem with just one function:\n",
    "   * input\n",
    "       * as per our input dataset, this NN has 4 inputs (X)\n",
    "   * hidden layer(s)\n",
    "       * the hidden layer here has 8 nodes, and uses a rectifier (**relu**) activation function, which is a good practice\n",
    "   * output\n",
    "       * because we used a one-hot encoding for the dataset, the output layer must create 3 output values, one for each class. We use a **softmax** activation function in the output layer, to ensure the output values are in the range of 0 and 1 and may be used as predicted probabilities: the output value with the largest value will be taken as the class predicted by the model. Finally, the network uses the efficient **adam** GD optimization algorithm with a **logarithmic loss function**, which is called **categorical crossentropy** in Keras.   \n",
    "   \n",
    "Hence, the network topology of this simple 1-layer FCNN can be summarized as:\n",
    "\n",
    "    4 inputs -> 1 hidden layer with 8 nodes -> 3 outputs\n",
    "\n",
    "and it simplementation in Keras is as simple as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "150/150 [==============================] - 0s - loss: 1.2669 - acc: 0.3333     \n",
      "Epoch 2/10\n",
      "150/150 [==============================] - 0s - loss: 1.2421 - acc: 0.3333     \n",
      "Epoch 3/10\n",
      "150/150 [==============================] - 0s - loss: 1.2163 - acc: 0.3333     \n",
      "Epoch 4/10\n",
      "150/150 [==============================] - 0s - loss: 1.1940 - acc: 0.3333     \n",
      "Epoch 5/10\n",
      "150/150 [==============================] - 0s - loss: 1.1703 - acc: 0.3400     \n",
      "Epoch 6/10\n",
      "150/150 [==============================] - 0s - loss: 1.1435 - acc: 0.3867     \n",
      "Epoch 7/10\n",
      "150/150 [==============================] - 0s - loss: 1.1202 - acc: 0.4267     \n",
      "Epoch 8/10\n",
      "150/150 [==============================] - 0s - loss: 1.0980 - acc: 0.5333     \n",
      "Epoch 9/10\n",
      "150/150 [==============================] - 0s - loss: 1.0782 - acc: 0.6200     \n",
      "Epoch 10/10\n",
      "150/150 [==============================] - 0s - loss: 1.0615 - acc: 0.6467     \n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(8, input_dim=4, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "###\n",
    "#baseline_model()\n",
    "###\n",
    "#my_model = baseline_model()\n",
    "#0 history=model.fit(X, Y, epochs=10)\n",
    "#1 \n",
    "history=model.fit(X, transformed_Y, epochs=10)\n",
    "#2 history=model.fit(X, transformed_Y, epochs=100)\n",
    "#3 history=model.fit(X, transformed_Y, epochs=1000)\n",
    "#4 history=model.fit(X, transformed_Y, epochs=100, batch_size=32)\n",
    "#5 history=model.fit(X, transformed_Y, epochs=100, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 8)                 40        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 27        \n",
      "=================================================================\n",
      "Total params: 67\n",
      "Trainable params: 67\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1c3037df90>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "my_variable=history.history[\"acc\"]\n",
    "plt.plot(range(len(my_variable)),my_variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, transformed_Y, test_size=0.2, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 120 samples, validate on 30 samples\n",
      "Epoch 1/10\n",
      "120/120 [==============================] - 0s - loss: 3.5780 - acc: 0.3167 - val_loss: 3.4199 - val_acc: 0.4000\n",
      "Epoch 2/10\n",
      "120/120 [==============================] - 0s - loss: 3.4816 - acc: 0.3167 - val_loss: 3.3391 - val_acc: 0.4000\n",
      "Epoch 3/10\n",
      "120/120 [==============================] - 0s - loss: 3.3902 - acc: 0.3167 - val_loss: 3.2606 - val_acc: 0.4000\n",
      "Epoch 4/10\n",
      "120/120 [==============================] - 0s - loss: 3.3040 - acc: 0.3167 - val_loss: 3.1839 - val_acc: 0.4000\n",
      "Epoch 5/10\n",
      "120/120 [==============================] - 0s - loss: 3.2232 - acc: 0.3167 - val_loss: 3.1097 - val_acc: 0.4000\n",
      "Epoch 6/10\n",
      "120/120 [==============================] - 0s - loss: 3.1382 - acc: 0.3167 - val_loss: 3.0390 - val_acc: 0.4000\n",
      "Epoch 7/10\n",
      "120/120 [==============================] - 0s - loss: 3.0600 - acc: 0.3167 - val_loss: 2.9708 - val_acc: 0.4000\n",
      "Epoch 8/10\n",
      "120/120 [==============================] - 0s - loss: 2.9855 - acc: 0.3167 - val_loss: 2.9048 - val_acc: 0.4000\n",
      "Epoch 9/10\n",
      "120/120 [==============================] - 0s - loss: 2.9115 - acc: 0.3167 - val_loss: 2.8421 - val_acc: 0.4000\n",
      "Epoch 10/10\n",
      "120/120 [==============================] - 0s - loss: 2.8403 - acc: 0.3167 - val_loss: 2.7820 - val_acc: 0.4000\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(8, input_dim=4, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "###\n",
    "#baseline_model()\n",
    "###\n",
    "#my_model = baseline_model()\n",
    "#0 history=model.fit(X_train, Y_train, epochs=10, validation_data=(X_test,Y_test))\n",
    "#1 \n",
    "history=model.fit(X_train, Y_train, epochs=10, validation_data=(X_test,Y_test))\n",
    "#2 history=model.fit(X_train, Y_train, epochs=100, validation_data=(X_test,Y_test))\n",
    "#3 history=model.fit(X_train, Y_train, epochs=1000, validation_data=(X_test,Y_test))\n",
    "#4 history=model.fit(X_train, Y_train, epochs=100, validation_data=(X_test,Y_test), batch_size=32)\n",
    "#5 history=model.fit(X_train, Y_train, epochs=100, validation_data=(X_test,Y_test), batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1c30ca1ad0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "variable1=history.history[\"loss\"]\n",
    "variable2=history.history[\"val_loss\"]\n",
    "plt.plot(range(len(variable1)),variable1, label='loss')\n",
    "plt.plot(range(len(variable2)),variable2, label='val_loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 8)                 40        \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 3)                 27        \n",
      "=================================================================\n",
      "Total params: 67\n",
      "Trainable params: 67\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1 (difficulty: easy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat the same using only the last 100 entries of the dataset.\n",
    "   * Are you able to understand how the problem is modified by this choice, and which code changes are necessary to make this notebook work still?\n",
    "   * Are you able to interpret the results you get?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2 (difficulty: moderate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use KerasClassifier\n",
    "\n",
    "\n",
    "The idea here is to use the Keras library which provides wrapper classes to allow you to use NN models developed with Keras (see cell above) in scikit-learn. Why so? Because Keras is simple, and scikit-learn is powerful and versatile!\n",
    "\n",
    "There is a *KerasClassifier* class in Keras that can be used as an *Estimator* in scikit-learn, the base type of model in the library. We need to actually create our KerasClassifier first, to be used in scikit-learn. KerasClassifier takes the name of a function (the one we wrote above) as an argument, plus arguments that will be passed on to the *fit()* function internally used to train the NN. Here, we pass:\n",
    "\n",
    "* a number of epochs as 200\n",
    "* a batch size as 5 \n",
    "\n",
    "to use when training the model. Debugging is also turned off when training by setting verbose to 0.\n",
    "    \n",
    "This function returns the constructed NN model, ready for training.\n",
    "\n",
    "Hint: https://keras.io/scikit-learn-api/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## INSERT YOUR CODE HERE\n",
    "\n",
    "# insert here a new function named baseline_model that creates the model \n",
    "# used in the notebook above, and just returns it as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## INSERT YOUR CODE HERE\n",
    "\n",
    "# create an \"estimator\" object that works as a KerasClassifier with the parameters suggested above\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate The Model with $k$-Fold Cross-Validation\n",
    "\n",
    "It is time to evaluate our NN model on our training data, a.k.a. the \"training\" phase.\n",
    "\n",
    "The scikit-learn library has excellent capability to evaluate models using a suite of techniques. The gold standard for evaluating ML models is **k-fold cross-validation (k-fold CV)**. We do as follows:\n",
    "\n",
    "1. we define the model evaluation procedure.\n",
    "      * here, we shuffle the data before partitioning it, and we set the number of folds to 10 (a good default)\n",
    "     \n",
    "     \n",
    "2. we evaluate our model (*estimator*) on our dataset (*X* and *transformed_Y*) using a 10-fold CV procedure (kfold)\n",
    "\n",
    "Evaluating the model only takes approximately 10 seconds and returns an object that describes the evaluation of the k=10 constructed models for each of the splits of the dataset. \n",
    "\n",
    "The results are summarized as both the mean and standard deviation of the model accuracy on the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# part 1\n",
    "## INSERT YOUR CODE HERE\n",
    "\n",
    "# create a \"kfold\" object (hint: search for scikit-learn KFold in the documentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# part 2\n",
    "## INSERT YOUR CODE HERE\n",
    "\n",
    "# create an object \"results\" by using \"cross_val_score\" in scikit-learn \n",
    "# and print printout mean and std dev of the accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a reasonable estimation of the performance of the model on unseen data. It is also within the realm of known top results for this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary \n",
    "\n",
    "What we learned:\n",
    "\n",
    "* how to develop and evaluate a NN using the Keras library for ML/DL.\n",
    "\n",
    "Specifically:\n",
    "\n",
    "* How to load data and make it available to Keras\n",
    "* How to prepare multiclass classification data for modeling using one hot encoding\n",
    "* How to use Keras NN models with scikit-learn\n",
    "* How to define a NN using Keras for multiclass classification\n",
    "* How to evaluate a Keras NN model using scikit-learn with k-fold cross-validation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
